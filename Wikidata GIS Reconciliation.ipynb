{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac00893",
   "metadata": {},
   "source": [
    "# GIS Reconciliation for Wikidata\n",
    "This notebook does the following:\n",
    "\n",
    "1. Downloads a dataset from an ArcGIS FeatureServer REST API.\n",
    "2. Converts all of the polygon data to a single point that is useful for Wikidata.\n",
    "3. Attempts to find matching OpenStreetMap entities in the same place as the GIS data.\n",
    "4. Writes it all out as a CSV that can be imported to OpenRefine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd53020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ef0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "GIS_SERVER_BASE_URL = 'https://gis.ccc.govt.nz/server/rest/services/OpenData/GreenAsset/FeatureServer/12/query'\n",
    "\n",
    "logging.info(\"Retrieving data from GIS API\")\n",
    "raw_api_response = requests.get(\n",
    "    GIS_SERVER_BASE_URL,\n",
    "    params={\n",
    "        'where': '1=1',                                  # cheeky trick to just get everything the server has\n",
    "        'geometryType': 'esriGeometryEnvelope',\n",
    "        'spatialRel': 'esriSpatialRelIntersects',\n",
    "        'units': 'esriSRUnit_Metre',\n",
    "        'outFields': '*',                                # get everything the server has\n",
    "        'returnGeometry': 'true',                        # make sure we get the polygons\n",
    "        'returnCentroid': 'true',                        # not very useful but may as well\n",
    "        'f': 'geoJson',                                  # we need this format\n",
    "    }\n",
    ")\n",
    "\n",
    "raw_api_response.raise_for_status()\n",
    "\n",
    "raw_geojson = raw_api_response.json()\n",
    "logging.info(f\"Retrieved {len(raw_geojson['features'])} objects from GIS API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f19cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute polylabels for all retrieved objects\n",
    "\n",
    "If an object is a polygon, we want to coerce that to a single point.\n",
    "This is because the Wikidata coordinate location (P625) property\n",
    "expects a single point. \n",
    "\n",
    "To do this, we compute the \"point of isolation\" (aka a polylabel) for\n",
    "the geometry. If the geometry is complex with multiple polygons we \n",
    "compute the polylabel for the largest polygon.\n",
    "\n",
    "The polylabel represents (in most cases) the natural \"visual centre\" of\n",
    "an object and therefore is a good choice for using in Wikidata.\n",
    "\n",
    "NB: this process does not account for polygons with cutouts\n",
    "\"\"\"\n",
    "from functools import cmp_to_key\n",
    "from typing import List, Tuple\n",
    "\n",
    "from polylabel import polylabel\n",
    "from shapely.geometry import Point, LinearRing, Polygon\n",
    "\n",
    "COORD_PRECISION = 5  # more than 5 digits of precision is excessive for Wikidata\n",
    "POLYLABEL_PRECISION = 0.00001  # this is plenty enough to reliably find a PoI\n",
    "\n",
    "\n",
    "def convert_polygon(coordinates: List[Tuple[float, float]]) -> LinearRing:\n",
    "    # remember! latitude = y, longitude = x, so we specify things as lon,lat\n",
    "    points = [Point(lon, lat) for (lon, lat) in coordinates]\n",
    "    return LinearRing(points)\n",
    "\n",
    "entity_rows = []\n",
    "logging.info(f'Computing coordinate location for all entries')\n",
    "for park_response in raw_geojson[\"features\"]:\n",
    "    park_features = park_response[\"properties\"]\n",
    "    \n",
    "    if park_response[\"geometry\"][\"type\"] == \"MultiPolygon\":\n",
    "        # complex geometry, with multiple polygons\n",
    "        \n",
    "        # first, compute polylabels for all polygons\n",
    "        polygons = [convert_polygon(p[0]) for p in park_response[\"geometry\"][\"coordinates\"]]\n",
    "        \n",
    "        # get the polygons ordered by size\n",
    "        polygons = sorted(polygons, reverse=True, key=cmp_to_key(lambda p1, p2: Polygon(p1).area - Polygon(p2).area))\n",
    "        \n",
    "        coordinate_location = polylabel([polygons[0].coords], precision=POLYLABEL_PRECISION)\n",
    "    elif park_response[\"geometry\"][\"type\"] == \"Polygon\":\n",
    "        coordinate_location = polylabel(park_response[\"geometry\"][\"coordinates\"], precision=POLYLABEL_PRECISION)\n",
    "    elif park_response[\"geometry\"][\"type\"] == \"Point\":\n",
    "        coordinate_location = park_response[\"geometry\"][\"coordinates\"]\n",
    "    else:\n",
    "        continue\n",
    "    park_features['coordinate_location'] = f'{round(coordinate_location[1], COORD_PRECISION)},{round(coordinate_location[0], COORD_PRECISION)}'\n",
    "    entity_rows.append(park_features)\n",
    "        \n",
    "logging.info(f'Converted {len(entity_rows)} entries')\n",
    "                                                        \n",
    "                                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a200bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualise the data you just generated\n",
    "\n",
    "Hover over points to see the park name. This can be handy\n",
    "jsut for verifying that everything looks roughly the way\n",
    "you expect it to.\n",
    "\"\"\"\n",
    "from ipyleaflet import Map, Marker\n",
    "from ipywidgets import HTML\n",
    "import json\n",
    "\n",
    "coords = [p['coordinate_location'].split(',') for p in park_rows]\n",
    "avg_lat = sum([float(c[0]) for c in coords]) / len(coords)\n",
    "avg_lon = sum([float(c[1]) for c in coords]) / len(coords)\n",
    "\n",
    "m = Map(center=(avg_lat, avg_lon), zoom=10)\n",
    "\n",
    "for p in entity_rows:\n",
    "    coord = p['coordinate_location'].split(',')\n",
    "    marker = Marker(location=(float(coord[0]), float(coord[1])), draggable=False)\n",
    "    marker.title = p['ParkName']\n",
    "    m.add(marker)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4eecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build a database of potentially interesting OSM objects\n",
    "\n",
    "NB: Currently not working for relations. There is a bit more \n",
    "processing needed to compute all the polygons of a relation.\n",
    "\"\"\"\n",
    "\n",
    "import overpass\n",
    "\n",
    "osm_api = overpass.API()\n",
    "\n",
    "# map of OSM tags and allowed values\n",
    "# if a way or relation matches of any of these, it will be captured\n",
    "target_tags = {\n",
    "    'leisure': [\n",
    "        'nature_reserve',\n",
    "        'park',\n",
    "    ],\n",
    "    'landuse': [\n",
    "        'forest',\n",
    "        'cemetery',\n",
    "    ],\n",
    "    'boundary': [\n",
    "        'protected_area',\n",
    "    ]\n",
    "}\n",
    "\n",
    "coords = [p['coordinate_location'].split(',') for p in park_rows]\n",
    "sw_lat = min([float(c[0]) for c in coords])\n",
    "sw_lon = min([float(c[1]) for c in coords])\n",
    "\n",
    "ne_lat = max([float(c[0]) for c in coords])\n",
    "ne_lon = max([float(c[1]) for c in coords])\n",
    "\n",
    "bbox = f'({sw_lat - 0.0001},{sw_lon - 0.0001},{ne_lat + 0.0001},{ne_lon + 0.0001})'\n",
    "\n",
    "filter_strings = [f'{t}~\\'{\"|\".join(v)}\\'' for t,v in target_tags.items()]\n",
    "f_parts = [f'way[{f}]{bbox}' for f in filter_strings]\n",
    "f_parts += [f'relation[{f}]{bbox}' for f in filter_strings]\n",
    "filter_str = ';\\n'.join(f_parts) + ';'\n",
    "\n",
    "avg_lat = sum([float(c[0]) for c in coords]) / len(coords)\n",
    "avg_lon = sum([float(c[1]) for c in coords]) / len(coords)\n",
    "\n",
    "overpass_query = f'''\n",
    "        (\n",
    "        {filter_str}\n",
    "        );\n",
    "        (._;>;);'''\n",
    "\n",
    "logging.debug('Issuing Overpass query: %s', overpass_query)\n",
    "overpass_response = osm_api.Get(overpass_query, responseformat='json')\n",
    "logging.info('Downloaded all data from Overpass, beginning data cleaning')\n",
    "\n",
    "raw_way_data = list(filter(lambda e: e['type'] != 'node', overpass_response['elements']))\n",
    "\n",
    "# create a dict for faster lookup\n",
    "node_data = {n['id']: n for n in overpass_response['elements'] if n['type'] == 'node'}\n",
    "\n",
    "ways_data: List = list()\n",
    "    \n",
    "for way in raw_way_data:\n",
    "    nodes = way.get('nodes', None)\n",
    "    if not nodes or len(nodes) < 3:\n",
    "        continue\n",
    "    way_nodes = []\n",
    "    for n in nodes:\n",
    "        node = node_data[n]\n",
    "        way_nodes.append((node['lon'], node['lat']))\n",
    "    osm_object = {\n",
    "        'id': way['id'],\n",
    "        'type': way['type'],\n",
    "        'name': way.get('tags', {}).get('name'),\n",
    "        'qid': way.get('tags', {}).get('wikidata'),\n",
    "        'polygon': Polygon(way_nodes),\n",
    "    }\n",
    "    ways_data.append(osm_object)\n",
    "del raw_way_data  # bit of a memory hog\n",
    "logging.info('Created a database of potential OpenStreetMap matches')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d09701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reconcile between the GIS data and OSM data geospatially\n",
    "\n",
    "Finds OSM objects that contain our chosen polylabel point.\n",
    "\"\"\"\n",
    "logging.info('Matching GIS objects to OSM objects')\n",
    "matches = 0\n",
    "for p in entity_rows:\n",
    "    # there has to be a faster algo for this\n",
    "    # maybe some binary search magic\n",
    "    # but for now my CPU will suffer\n",
    "    lat, lon = p['coordinate_location'].split(',')\n",
    "    candidates = list(filter(lambda w: w['polygon'].contains(Point(lon, lat)), ways_data))\n",
    "    if not candidates:\n",
    "        continue\n",
    "    if len(candidates) > 1:\n",
    "        logging.debug(f'Found multiple potential OSM matches')\n",
    "    candidate = candidates[0]\n",
    "    p['osm_way_id' if candidate['type'] == 'way' else 'osm_rel_id'] = str(candidate['id'])\n",
    "    p['osm_qid'] = candidate['qid']\n",
    "    p['osm_name'] = candidate['name']\n",
    "    matches += 1\n",
    "logging.info('Finished matching GIS objects to OSM objects')\n",
    "logging.info(f'Found {matches} potential matches for {len(park_rows)} records ({round((matches/len(park_rows))*100,1)}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb00852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "View and export data table\n",
    "\"\"\"\n",
    "import pandas\n",
    "\n",
    "df = pandas.DataFrame.from_dict(entity_rows)\n",
    "df.to_csv('target/output.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c81b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
